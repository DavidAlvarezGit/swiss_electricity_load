{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3500e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def read_correct_sheet(file):\n",
    "    xls = pd.ExcelFile(file)\n",
    "\n",
    "    # Pick Zeitreihen sheet (Swissgrid time series)\n",
    "    for name in xls.sheet_names:\n",
    "        n = name.lower().replace(\" \", \"\")\n",
    "        if \"zeitreihen\" in n:\n",
    "            return pd.read_excel(file, sheet_name=name, header=0)\n",
    "\n",
    "    # Fallback: first sheet\n",
    "    return pd.read_excel(file, sheet_name=0, header=0)\n",
    "\n",
    "\n",
    "def merge_swissgrid_excels(folder, output_file):\n",
    "    folder = Path(folder)\n",
    "\n",
    "    # Read both .xls and .xlsx\n",
    "    files = sorted(list(folder.glob(\"*.xls\")) + list(folder.glob(\"*.xlsx\")))\n",
    "\n",
    "    if not files:\n",
    "        raise ValueError(\"No Excel files found\")\n",
    "\n",
    "    print(\"Found\", len(files), \"files\")\n",
    "\n",
    "    # First file defines column structure\n",
    "    base = read_correct_sheet(files[0])\n",
    "    cols = base.columns\n",
    "\n",
    "    frames = [base]\n",
    "\n",
    "    for f in files[1:]:\n",
    "        print(\"Reading\", f.name)\n",
    "        df = read_correct_sheet(f)\n",
    "        df = df.reindex(columns=cols)\n",
    "        frames.append(df)\n",
    "\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "    merged.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"Saved ->\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8211aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 files\n",
      "Reading EnergieUebersichtCH-2010.xls\n",
      "Reading EnergieUebersichtCH-2011.xls\n",
      "Reading EnergieUebersichtCH-2012.xls\n",
      "Reading EnergieUebersichtCH-2013.xls\n",
      "Reading EnergieUebersichtCH-2014.xls\n",
      "Reading EnergieUebersichtCH-2015.xls\n",
      "Reading EnergieUebersichtCH-2016.xls\n",
      "Reading EnergieUebersichtCH-2017.xls\n",
      "Reading EnergieUebersichtCH-2018.xls\n",
      "Reading EnergieUebersichtCH-2019.xls\n",
      "Reading EnergieUebersichtCH-2020.xlsx\n",
      "Reading EnergieUebersichtCH-2021.xlsx\n",
      "Reading EnergieUebersichtCH-2022.xlsx\n",
      "Reading EnergieUebersichtCH-2023.xlsx\n",
      "Reading EnergieUebersichtCH-2024.xlsx\n",
      "Reading EnergieUebersichtCH-2025.xlsx\n",
      "Reading EnergieUebersichtCH-2026.xlsx\n",
      "Saved -> ../data/processed/swissgrid_all_years.csv\n"
     ]
    }
   ],
   "source": [
    "merge_swissgrid_excels(\n",
    "    folder=\"../data/raw\",   # where Excel files are\n",
    "    output_file=\"../data/processed/swissgrid_all_years.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6ea49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_33048\\1285177842.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026 appended successfully. Rows: 598,971\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "SWISSGRID_URL_TEMPLATE = (\n",
    "    \"https://www.swissgrid.ch/content/dam/dataimport/energy-statistic/\"\n",
    "    \"EnergieUebersichtCH-{year}.{ext}\"\n",
    ")\n",
    "\n",
    "\n",
    "def _coerce_datetime_column(df):\n",
    "    candidates = [df.columns[0]]\n",
    "\n",
    "    for col in df.columns:\n",
    "        lower = str(col).lower()\n",
    "        if \"date\" in lower or \"time\" in lower or lower.startswith(\"unnamed\"):\n",
    "            if col not in candidates:\n",
    "                candidates.append(col)\n",
    "\n",
    "    best_col = None\n",
    "    best_parsed = None\n",
    "    best_ratio = -1.0\n",
    "\n",
    "    for col in candidates:\n",
    "        parsed = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "        ratio = parsed.notna().mean()\n",
    "        if ratio > best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_col = col\n",
    "            best_parsed = parsed\n",
    "\n",
    "    if best_col is None or best_ratio < 0.95:\n",
    "        raise ValueError(\"Could not reliably identify datetime column\")\n",
    "\n",
    "    return best_col, best_parsed\n",
    "\n",
    "\n",
    "def fetch_and_append_year(year, output_file):\n",
    "    output_file = Path(output_file)\n",
    "\n",
    "    if not output_file.exists():\n",
    "        raise ValueError(\"Existing CSV not found. Run merge first.\")\n",
    "\n",
    "    # 1) Download file\n",
    "    content = None\n",
    "\n",
    "    for ext in [\"xlsx\", \"xls\"]:\n",
    "        url = SWISSGRID_URL_TEMPLATE.format(year=year, ext=ext)\n",
    "        r = requests.get(url, timeout=90)\n",
    "\n",
    "        if r.status_code == 404:\n",
    "            continue\n",
    "\n",
    "        r.raise_for_status()\n",
    "        if r.content:\n",
    "            content = r.content\n",
    "            break\n",
    "\n",
    "    if content is None:\n",
    "        raise ValueError(f\"No file available for {year}\")\n",
    "\n",
    "    # 2) Read sheet\n",
    "    df_new = read_correct_sheet(BytesIO(content))\n",
    "\n",
    "    # 3) Load historical\n",
    "    hist = pd.read_csv(output_file, low_memory=False)\n",
    "\n",
    "    # Align columns strictly\n",
    "    df_new = df_new.reindex(columns=hist.columns)\n",
    "\n",
    "    # 4) Concatenate\n",
    "    merged = pd.concat([hist, df_new], ignore_index=True)\n",
    "\n",
    "    # 5) Parse datetime and deduplicate\n",
    "    dt_col, dt_values = _coerce_datetime_column(merged)\n",
    "    merged[dt_col] = dt_values\n",
    "    merged = merged.dropna(subset=[dt_col])\n",
    "    merged = merged.sort_values(dt_col)\n",
    "    merged = merged.drop_duplicates(subset=[dt_col], keep=\"last\")\n",
    "    merged = merged.reset_index(drop=True)\n",
    "\n",
    "    # 6) Save\n",
    "    merged.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"{year} appended successfully. Rows: {len(merged):,}\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "df = fetch_and_append_year(2026, \"../data/processed/swissgrid_all_years.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6cc105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "# City coordinates\n",
    "CITIES = {\n",
    "    \"zurich\": (47.3769, 8.5417),\n",
    "    \"geneva\": (46.2044, 6.1432),\n",
    "    \"basel\": (47.5596, 7.5886),\n",
    "    \"bern\": (46.9480, 7.4474),\n",
    "    \"lausanne\": (46.5197, 6.6323),\n",
    "    \"lugano\": (46.0037, 8.9511),\n",
    "}\n",
    "\n",
    "# Approximate population weights\n",
    "WEIGHTS = {\n",
    "    \"zurich\": 0.30,\n",
    "    \"geneva\": 0.18,\n",
    "    \"basel\": 0.15,\n",
    "    \"bern\": 0.15,\n",
    "    \"lausanne\": 0.12,\n",
    "    \"lugano\": 0.10,\n",
    "}\n",
    "\n",
    "NASA_URL = (\n",
    "    \"https://power.larc.nasa.gov/api/temporal/hourly/point\"\n",
    "    \"?parameters=T2M\"\n",
    "    \"&community=RE\"\n",
    "    \"&longitude={lon}\"\n",
    "    \"&latitude={lat}\"\n",
    "    \"&start={start}\"\n",
    "    \"&end={end}\"\n",
    "    \"&format=JSON\"\n",
    ")\n",
    "\n",
    "\n",
    "def _fetch_json_with_retry(url, timeout=60, retries=3, sleep_seconds=2):\n",
    "    last_err = None\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except requests.RequestException as err:\n",
    "            last_err = err\n",
    "            if attempt < retries:\n",
    "                time.sleep(sleep_seconds)\n",
    "    raise RuntimeError(f\"Request failed after {retries} attempts: {url}\") from last_err\n",
    "\n",
    "\n",
    "def fetch_weather(start_year=2009):\n",
    "    end_year = datetime.now().year\n",
    "    all_cities_data = []\n",
    "\n",
    "    for city, (lat, lon) in CITIES.items():\n",
    "        print(\"Fetching:\", city)\n",
    "        city_frames = []\n",
    "\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            start = f\"{year}0101\"\n",
    "            end = f\"{year}1231\"\n",
    "\n",
    "            # For current year, stop at yesterday to avoid partial current-day data\n",
    "            if year == end_year:\n",
    "                end_date = datetime.now() - timedelta(days=1)\n",
    "                if end_date.year < year:\n",
    "                    continue\n",
    "                end = end_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "            url = NASA_URL.format(lon=lon, lat=lat, start=start, end=end)\n",
    "            json_data = _fetch_json_with_retry(url)\n",
    "\n",
    "            if \"properties\" not in json_data or \"parameter\" not in json_data[\"properties\"]:\n",
    "                print(\"No data for:\", city, year)\n",
    "                continue\n",
    "\n",
    "            data = json_data[\"properties\"][\"parameter\"].get(\"T2M\", {})\n",
    "            if not data:\n",
    "                print(\"No T2M data for:\", city, year)\n",
    "                continue\n",
    "\n",
    "            df_year = pd.DataFrame({\n",
    "                \"datetime\": pd.to_datetime(list(data.keys()), format=\"%Y%m%d%H\"),\n",
    "                city: list(data.values()),\n",
    "            })\n",
    "\n",
    "            df_year[city] = df_year[city].replace(-999, pd.NA)\n",
    "            city_frames.append(df_year)\n",
    "\n",
    "        if not city_frames:\n",
    "            raise ValueError(f\"No data fetched for {city}\")\n",
    "\n",
    "        df_city = pd.concat(city_frames, ignore_index=True)\n",
    "        all_cities_data.append(df_city)\n",
    "\n",
    "    # Merge city time series\n",
    "    df_weather = all_cities_data[0]\n",
    "    for df in all_cities_data[1:]:\n",
    "        df_weather = df_weather.merge(df, on=\"datetime\", how=\"inner\")\n",
    "\n",
    "    # Clean\n",
    "    for city in CITIES:\n",
    "        df_weather[city] = pd.to_numeric(df_weather[city], errors=\"coerce\")\n",
    "\n",
    "    df_weather = df_weather.dropna()\n",
    "\n",
    "    # Weighted temperature and derived features\n",
    "    df_weather[\"temp_weighted\"] = sum(df_weather[c] * WEIGHTS[c] for c in CITIES)\n",
    "    df_weather[\"HDH\"] = (18 - df_weather[\"temp_weighted\"]).clip(lower=0)\n",
    "    df_weather[\"CDH\"] = (df_weather[\"temp_weighted\"] - 22).clip(lower=0)\n",
    "    df_weather[\"temp_72h\"] = df_weather[\"temp_weighted\"].rolling(72, min_periods=1).mean()\n",
    "    df_weather[\"extreme_cold\"] = (df_weather[\"temp_weighted\"] < -5).astype(int)\n",
    "\n",
    "    return df_weather.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7309bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: zurich\n",
      "Fetching: geneva\n",
      "Fetching: basel\n",
      "Fetching: bern\n",
      "Fetching: lausanne\n",
      "Fetching: lugano\n"
     ]
    }
   ],
   "source": [
    "df_weather = fetch_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c517c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>zurich</th>\n",
       "      <th>geneva</th>\n",
       "      <th>basel</th>\n",
       "      <th>bern</th>\n",
       "      <th>lausanne</th>\n",
       "      <th>lugano</th>\n",
       "      <th>temp_weighted</th>\n",
       "      <th>HDH</th>\n",
       "      <th>CDH</th>\n",
       "      <th>temp_72h</th>\n",
       "      <th>extreme_cold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:00:00</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>-2.7081</td>\n",
       "      <td>20.7081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.708100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 01:00:00</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-4.15</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>-4.68</td>\n",
       "      <td>-4.89</td>\n",
       "      <td>-2.9901</td>\n",
       "      <td>20.9901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.849100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 02:00:00</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-4.65</td>\n",
       "      <td>-5.43</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>-3.4313</td>\n",
       "      <td>21.4313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.043167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 03:00:00</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>-4.89</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>-3.9597</td>\n",
       "      <td>21.9597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.272300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 04:00:00</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>-3.63</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>-5.96</td>\n",
       "      <td>-7.23</td>\n",
       "      <td>-4.51</td>\n",
       "      <td>-4.5190</td>\n",
       "      <td>22.5190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.521640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150139</th>\n",
       "      <td>2026-02-19 19:00:00</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.8353</td>\n",
       "      <td>16.1647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150140</th>\n",
       "      <td>2026-02-19 20:00:00</td>\n",
       "      <td>3.37</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.6715</td>\n",
       "      <td>16.3285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150141</th>\n",
       "      <td>2026-02-19 21:00:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>1.4036</td>\n",
       "      <td>16.5964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150142</th>\n",
       "      <td>2026-02-19 22:00:00</td>\n",
       "      <td>2.32</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>1.2036</td>\n",
       "      <td>16.7964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150143</th>\n",
       "      <td>2026-02-19 23:00:00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>1.1213</td>\n",
       "      <td>16.8787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150144 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  zurich  geneva  basel  bern  lausanne  lugano  \\\n",
       "0      2009-01-01 00:00:00   -1.60   -1.11  -3.80 -3.13     -3.89   -5.22   \n",
       "1      2009-01-01 01:00:00   -1.60   -1.45  -4.15 -3.84     -4.68   -4.89   \n",
       "2      2009-01-01 02:00:00   -1.96   -1.99  -4.52 -4.65     -5.43   -4.58   \n",
       "3      2009-01-01 03:00:00   -2.43   -2.84  -4.89 -5.34     -6.25   -4.35   \n",
       "4      2009-01-01 04:00:00   -2.89   -3.63  -5.24 -5.96     -7.23   -4.51   \n",
       "...                    ...     ...     ...    ...   ...       ...     ...   \n",
       "150139 2026-02-19 19:00:00    3.36   -0.13   3.80  1.49      0.26    0.26   \n",
       "150140 2026-02-19 20:00:00    3.37   -0.14   3.50  1.19      0.21   -0.43   \n",
       "150141 2026-02-19 21:00:00    2.75   -0.16   3.39  1.11      0.17   -0.88   \n",
       "150142 2026-02-19 22:00:00    2.32   -0.18   3.39  1.07      0.05   -1.35   \n",
       "150143 2026-02-19 23:00:00    2.24   -0.20   3.42  1.05     -0.16   -1.66   \n",
       "\n",
       "        temp_weighted      HDH  CDH  temp_72h  extreme_cold  \n",
       "0             -2.7081  20.7081  0.0 -2.708100             0  \n",
       "1             -2.9901  20.9901  0.0 -2.849100             0  \n",
       "2             -3.4313  21.4313  0.0 -3.043167             0  \n",
       "3             -3.9597  21.9597  0.0 -3.272300             0  \n",
       "4             -4.5190  22.5190  0.0 -3.521640             0  \n",
       "...               ...      ...  ...       ...           ...  \n",
       "150139         1.8353  16.1647  0.0  0.661831             0  \n",
       "150140         1.6715  16.3285  0.0  0.679201             0  \n",
       "150141         1.4036  16.5964  0.0  0.697281             0  \n",
       "150142         1.2036  16.7964  0.0  0.712878             0  \n",
       "150143         1.1213  16.8787  0.0  0.725961             0  \n",
       "\n",
       "[150144 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiss-electricity-load-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
